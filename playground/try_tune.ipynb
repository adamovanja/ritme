{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out raytune with scikit & keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import callbacks, layers, models, optimizers\n",
    "\n",
    "from q2_time.model import split_data_by_host\n",
    "from q2_time.simulate_data import simulate_data\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a simulated dataset\n",
    "host_id = \"host_id\"\n",
    "target = \"age_days\"\n",
    "train_size = 0.8\n",
    "seed = 12\n",
    "\n",
    "ft, md = simulate_data(100)\n",
    "data = md.join(ft, how=\"left\")\n",
    "data.sort_values([host_id, target], inplace=True)\n",
    "\n",
    "# todo: consider to split train into train - val during training\n",
    "# (train+val) & test split\n",
    "train_val, test = split_data_by_host(data, host_id, train_size, seed)\n",
    "X_test, y_test = test[ft.columns], test[target]\n",
    "\n",
    "# train & val split\n",
    "train, val = split_data_by_host(train_val, host_id, train_size, seed)\n",
    "X_train, y_train = train[ft.columns], train[target]\n",
    "X_val, y_val = val[ft.columns], val[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! define training functions\n",
    "\n",
    "\n",
    "# Define a training function for RandomForest\n",
    "def train_rf(config, X_train, y_train, X_val, y_val, seed):\n",
    "    # setting seed for scikit library\n",
    "    np.random.seed(seed)\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=config[\"n_estimators\"], max_depth=config[\"max_depth\"]\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    # train score\n",
    "    y_train_pred = rf.predict(X_train)\n",
    "    score_train = mean_squared_error(y_train, y_train_pred)\n",
    "    # val score\n",
    "    y_val_pred = rf.predict(X_val)\n",
    "    score_val = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    session.report({\"mse_val\": score_val, \"mse_train\": score_train})\n",
    "\n",
    "\n",
    "# Define a training function for Keras neural network\n",
    "def train_nn(config, X_train, y_train, X_val, y_val, seed):\n",
    "    # set seeds\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # define neural network\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "    n_layers = config[\"n_layers\"]\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = config[f\"n_units_l{i}\"]\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # define learning\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # train score\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    score_train = mean_squared_error(y_train, y_train_pred)\n",
    "    # val score\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    score_val = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    session.report({\"mse_val\": score_val, \"mse_train\": score_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! define search spaces\n",
    "# scikit random forest\n",
    "rf_space = {\n",
    "    \"n_estimators\": tune.randint(100, 1000),\n",
    "    \"max_depth\": tune.randint(2, 32),\n",
    "    \"min_samples_split\": tune.choice([0.0001, 0.001, 0.01, 0.1]),\n",
    "    \"min_samples_leaf\": tune.choice([0.00001, 0.0001, 0.001]),\n",
    "    \"max_features\": tune.choice([None, \"sqrt\", \"log2\", 0.1, 0.2, 0.5, 0.8]),\n",
    "    \"min_impurity_decrease\": tune.choice([0.0001, 0.001, 0.01]),\n",
    "    \"bootstrap\": tune.choice([True, False]),\n",
    "}\n",
    "\n",
    "# keras neural network\n",
    "nn_space = {\n",
    "    # Sample random uniformly between [1,9] rounding to multiples of 3\n",
    "    \"n_layers\": tune.qrandint(1, 9, 3),\n",
    "    \"learning_rate\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"batch_size\": tune.choice([32, 64, 128]),\n",
    "}\n",
    "for i in range(9):\n",
    "    nn_space[f\"n_units_l{i}\"] = tune.randint(3, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials(\n",
    "    trainable,\n",
    "    search_space,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    seed,\n",
    "    num_trials=5,\n",
    "    scheduler_grace_period=5,\n",
    "    scheduler_max_t=100,\n",
    "    resources={\"cpu\": 1},\n",
    "):\n",
    "    # set seed for search algorithms/schedulers\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # AsyncHyperBand enables aggressive early stopping of bad trials.\n",
    "    scheduler = AsyncHyperBandScheduler(\n",
    "        # Only stop trials at least this old in time (measured in training iteration)\n",
    "        grace_period=scheduler_grace_period,\n",
    "        # stopping trials after max_t iterations have passed\n",
    "        max_t=scheduler_max_t,\n",
    "    )\n",
    "\n",
    "    analysis_rf = tune.Tuner(\n",
    "        # trainable with input parameters passed and set resources\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(\n",
    "                trainable,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_val=X_val,\n",
    "                y_val=y_val,\n",
    "                seed=seed,\n",
    "            ),\n",
    "            resources,\n",
    "        ),\n",
    "        # hyperparameter space\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            # todo: consider taking RMSE loss\n",
    "            metric=\"mse_val\",\n",
    "            mode=\"min\",\n",
    "            # define the scheduler\n",
    "            scheduler=scheduler,\n",
    "            # number of trials to run\n",
    "            num_samples=num_trials,\n",
    "        ),\n",
    "    )\n",
    "    return analysis_rf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = run_trials(train_rf, rf_space, X_train, y_train, X_val, y_val, seed)\n",
    "print(\"Best hyperparameters found were: \", results_rf.get_best_result().config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn = run_trials(train_nn, nn_space, X_train, y_train, X_val, y_val, seed)\n",
    "print(\"Best hyperparameters found were: \", results_nn.get_best_result().config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raytune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
