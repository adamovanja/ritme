{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out raytune with scikit & keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import callbacks, layers, models, optimizers\n",
    "\n",
    "from q2_time.model import split_data_by_host\n",
    "from q2_time.simulate_data import simulate_data\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a simulated dataset\n",
    "host_id = \"host_id\"\n",
    "target = \"age_days\"\n",
    "train_size = 0.8\n",
    "seed = 12\n",
    "\n",
    "ft, md = simulate_data(100)\n",
    "data = md.join(ft, how=\"left\")\n",
    "data.sort_values([host_id, target], inplace=True)\n",
    "train, test = split_data_by_host(data, host_id, train_size, seed)\n",
    "\n",
    "X_train, y_train = train[ft.columns], train[target]\n",
    "X_test, y_test = test[ft.columns], test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a training function for RandomForest\n",
    "def train_rf(config, X_train, y_train, X_test, y_test, seed):\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=config[\"n_estimators\"], max_depth=config[\"max_depth\"]\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    session.report({\"rmse\": score})\n",
    "\n",
    "\n",
    "# Define a training function for Keras neural network\n",
    "def train_nn(config):\n",
    "    n_layers = config[\"n_layers\"]\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = config[f\"n_units_l{i}\"]\n",
    "        model.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    session.report({\"mse\": score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray Tune configuration for RandomForest\n",
    "rf_space = {\n",
    "    \"n_estimators\": tune.randint(100, 1000),\n",
    "    \"max_depth\": tune.randint(2, 32),\n",
    "    # sample a float uniformly between these two numbers while sampling in log space\n",
    "    # todo: find equivalent to previous values here! 0.001, 0.01, 0.1\n",
    "    \"min_samples_split\": tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "    \"min_samples_leaf\": tune.choice([0.00001, 0.0001]),\n",
    "    \"max_features\": tune.choice([None, \"sqrt\", \"log2\", 0.1, 0.2, 0.5, 0.8]),\n",
    "    \"min_impurity_decrease\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"bootstrap\": tune.choice([True, False]),\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning using Ray Tune\n",
    "num_trials = 5\n",
    "\n",
    "# set seed for search algorithms/schedulers\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# AsyncHyperBand enables aggressive early stopping of bad trials.\n",
    "scheduler = AsyncHyperBandScheduler(\n",
    "    # Only stop trials at least this old in time (measured in training iteration)\n",
    "    grace_period=5,\n",
    "    # stopping trials after max_t iterations have passed\n",
    "    max_t=100,\n",
    ")\n",
    "\n",
    "# todo: how to set seed?\n",
    "analysis_rf = tune.Tuner(\n",
    "    # trainable with input parameters passed and set resources\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(\n",
    "            train_rf,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            seed=seed,\n",
    "        ),\n",
    "        {\"cpu\": 1},\n",
    "    ),\n",
    "    # hyperparameter space\n",
    "    param_space=rf_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"rmse\",  # todo: adjust above\n",
    "        mode=\"min\",\n",
    "        # define the scheduler\n",
    "        scheduler=scheduler,\n",
    "        # number of trials to run\n",
    "        num_samples=num_trials,\n",
    "    ),\n",
    ")\n",
    "results_rf = analysis_rf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found were: \", results_rf.get_best_result().config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ray Tune configuration for Keras neural network\n",
    "# nn_space = {\n",
    "#     \"n_layers\": tune.randint(1, 3),\n",
    "#     \"learning_rate\": tune.loguniform(1e-5, 1e-1),\n",
    "# }\n",
    "# for i in range(3):\n",
    "#     nn_space[f\"n_units_l{i}\"] = tune.randint(4, 64)\n",
    "\n",
    "# # Tune Keras neural network hyperparameters\n",
    "# analysis_nn = tune.Tuner(\n",
    "#     train_nn,\n",
    "#     param_space=nn_space,\n",
    "#     tune_config=tune.TuneConfig(\n",
    "#         num_samples=num_trials,\n",
    "#         # which resource to use\n",
    "#         resources_per_trial=resources_per_trial,\n",
    "#     ),\n",
    "#     progress_reporter=reporter,\n",
    "#     name=\"nn_tuning\",\n",
    "# )\n",
    "# results_nn = analysis_nn.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raytune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
