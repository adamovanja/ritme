[tune] Best result metric not equal to metric calculated with Pytorch Lightning model of best result.

The Problem:
When I train a Pytorch Lightning model with Ray Tune and I extract the best result from the trials (`results.get_best_result()`), the retrieved best metric (in script `best_rmse_train`) is not equal to the metric I obtain when running the model of that best result checkpoint on the same data (`rmse_train_recalc`). However, `best_rmse_val` and `rmse_val_recalc` are identical.
Also, the counts on how often the metrics are logged differ between train and validation: train is only logged 9 times (`train_log_count`) whereas validation is logged 10 times (`val_log_count`).
Why is that? Is this a bug or is there a way to adjust TuneReportCheckpointCallback logging such that also `rmse_train` is logged 10 times and logged accurately.

Expected behavior:
I would expect both rmse_train metrics of the best result to be equal and the logs to be saved 10 times each.

Useful Information:
Please find attached a fully reproducible example of the code.

The script was run with these dependencies:
conda create -n ray_bug python==3.9 -y
conda activate ray_bug
conda install -c conda-forge -c pytorch pytorch==2.3.1 lightning==2.3.0 ray-default==2.24.0 ray-tune==2.24.0 -y
